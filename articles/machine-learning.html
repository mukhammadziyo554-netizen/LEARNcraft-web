<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="theme-color" content="#000000">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Machine Learning - LEARNcraft</title>
    <script src="https://telegram.org/js/telegram-web-app.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            background: #000000;
            color: #EAEAEA;
            min-height: 100vh;
        }

        .page-container {
            max-width: 900px;
            margin: 0 auto;
            padding: 80px 20px 60px;
        }

        .back-button {
            display: inline-block;
            padding: 10px 16px;
            background: transparent;
            border: none;
            color: #888;
            text-decoration: none;
            font-weight: 500;
            font-size: 14px;
            cursor: pointer;
            transition: color 0.3s;
            margin-bottom: 40px;
        }

        .back-button:hover {
            color: #EAEAEA;
        }

        .article-header {
            margin-bottom: 50px;
        }

        .article-title {
            font-size: 56px;
            font-weight: 700;
            color: #EAEAEA;
            margin-bottom: 12px;
            letter-spacing: -1px;
        }

        .article-subtitle {
            font-size: 20px;
            color: #888;
            font-weight: 400;
        }

        .intro-paragraph {
            font-size: 17px;
            line-height: 1.7;
            color: #EAEAEA;
            margin: 40px 0 30px 0;
        }

        .explore-button {
            display: inline-block;
            margin: 30px 0;
            padding: 12px 28px;
            background: transparent;
            border: 2px solid #FFD84D;
            color: #FFD84D;
            border-radius: 30px;
            text-decoration: none;
            font-weight: 600;
            font-size: 15px;
            cursor: pointer;
            transition: all 0.3s;
        }

        .explore-button:hover {
            background: #FFD84D;
            color: #000000;
            transform: translateY(-2px);
        }

        .article-content {
            margin-top: 50px;
        }

        .section {
            margin-bottom: 50px;
        }

        .section-title {
            font-size: 28px;
            font-weight: 700;
            color: #EAEAEA;
            margin-bottom: 16px;
            padding-bottom: 12px;
            border-bottom: 1px solid #222;
        }

        .section-content {
            font-size: 16px;
            line-height: 1.7;
            color: #EAEAEA;
        }

        .section-content p {
            margin-bottom: 18px;
        }

        .subsection {
            margin-top: 28px;
            margin-bottom: 20px;
        }

        .subsection-title {
            font-size: 18px;
            font-weight: 600;
            color: #FFD84D;
            margin-bottom: 10px;
        }

        .subsection-text {
            font-size: 16px;
            line-height: 1.7;
            color: #EAEAEA;
            margin-bottom: 12px;
        }

        .highlight-box {
            background: rgba(255, 216, 77, 0.08);
            border-left: 3px solid #FFD84D;
            padding: 16px 20px;
            margin: 24px 0;
        }

        .highlight-box p {
            margin: 0;
            color: #EAEAEA;
            font-size: 16px;
            line-height: 1.6;
        }

        ul {
            margin: 16px 0;
            padding-left: 24px;
        }

        ul li {
            margin-bottom: 10px;
            line-height: 1.6;
        }

        @media (max-width: 768px) {
            .page-container {
                padding: 70px 16px 40px;
            }

            .article-title {
                font-size: 40px;
            }

            .article-subtitle {
                font-size: 18px;
            }

            .section-title {
                font-size: 24px;
            }
        }
    </style>
</head>
<body>
    <div class="page-container">
        <button onclick="if (document.referrer && document.referrer !== '') { window.history.back(); } else { window.location.href = '../courses/learn.html'; }" class="back-button">‚Üê Back</button>
        
        <div class="article-header">
            <h1 class="article-title">Machine Learning</h1>
            <p class="article-subtitle">Empowering computers to learn from data and make intelligent decisions</p>
        </div>

        <p class="intro-paragraph">
            Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.
        </p>

        <p class="intro-paragraph">
            ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.
        </p>

        <button class="explore-button" onclick="window.location.href='../courses/learn.html'">Explore More Topics</button>

        <div class="article-content">
            <div class="section">
                <h2 class="section-title">History</h2>
                <div class="section-content">
                    <p>The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence. The synonym self-teaching computers was also used during this time period.</p>
                    
                    <div class="subsection">
                        <h3 class="subsection-title">Early Foundations (1940s-1950s)</h3>
                        <p class="subsection-text">The earliest machine learning program was introduced in the 1950s when Arthur Samuel invented a computer program that calculated the winning chance in checkers for each side, but the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.</p>
                        <p class="subsection-text">In 1949, Canadian psychologist Donald Hebb published the book "The Organization of Behavior," in which he introduced a theoretical neural structure formed by certain interactions among nerve cells. Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Development Era (1960s-1970s)</h3>
                        <p class="subsection-text">By the early 1960s, an experimental "learning machine" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyse sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively "trained" by a human operator/teacher to recognise patterns and equipped with a "goof" button to cause it to reevaluate incorrect decisions.</p>
                        <p class="subsection-text">Interest related to pattern recognition continued into the 1970s. In 1981, a report was given on using teaching strategies so that an artificial neural network learns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Modern Era (1990s-Present)</h3>
                        <p class="subsection-text">Machine learning (ML), reorganised and recognised as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic, and probability theory.</p>
                        <p class="subsection-text">In 2014, Ian Goodfellow and others introduced generative adversarial networks (GANs) with realistic data synthesis. By 2016, AlphaGo obtained victory against top human players using reinforcement learning techniques.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Formal Definition</h2>
                <div class="section-content">
                    <div class="highlight-box">
                        <p>Tom M. Mitchell provided a widely quoted, more formal definition: "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E."</p>
                    </div>
                    <p>This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper "Computing Machinery and Intelligence", in which the question, "Can machines think?", is replaced with the question, "Can machines do what we (as thinking entities) can do?".</p>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Algorithm Types</h2>
                <div class="section-content">
                    <p>Modern-day Machine Learning algorithms are broken into 3 algorithm types:</p>
                    
                    <div class="subsection">
                        <h3 class="subsection-title">Supervised Learning Algorithms</h3>
                        <p class="subsection-text">Objectives include classification and regression. The computer is presented with example inputs and their desired outputs, given by a "teacher", and the goal is to learn a general rule that maps inputs to outputs.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Unsupervised Learning Algorithms</h3>
                        <p class="subsection-text">Objectives include clustering, dimensionality reduction, and association rule. No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Reinforcement Learning Algorithms</h3>
                        <p class="subsection-text">Focus on decisions that must be made with respect to some previous, unknown time and are broken down to either be studies of model-based methods or model-free methods. A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent).</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Relationships to Other Fields</h2>
                <div class="section-content">
                    <div class="subsection">
                        <h3 class="subsection-title">Artificial Intelligence</h3>
                        <p class="subsection-text">As a scientific endeavour, machine learning grew out of the quest for artificial intelligence (AI). Deep learning is a subset of machine learning, which is itself a subset of artificial intelligence. In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Data Compression</h3>
                        <p class="subsection-text">There is a close connection between machine learning and compression. A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression. Conversely, an optimal compressor can be used for prediction. This equivalence has been used as a justification for using data compression as a benchmark for "general intelligence".</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Data Mining</h3>
                        <p class="subsection-text">Machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Statistics</h3>
                        <p class="subsection-text">Machine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample, while machine learning finds generalisable predictive patterns.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Statistical Physics</h3>
                        <p class="subsection-text">Analytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyse the weight space of deep neural networks. Statistical physics is thus finding applications in the area of medical diagnostics.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Theory</h2>
                <div class="section-content">
                    <p>A core objective of a learner is to generalise from its experience. Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set.</p>
                    
                    <p>The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the probably approximately correct learning model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms.</p>

                    <div class="highlight-box">
                        <p>For the best performance in the context of generalisation, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has underfitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalisation will be poorer.</p>
                    </div>

                    <p>In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time.</p>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Supervised Learning</h2>
                <div class="section-content">
                    <p>Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs. The data, known as training data, consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal.</p>
                    
                    <p>Through iterative optimisation of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs. An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data.</p>

                    <div class="subsection">
                        <h3 class="subsection-title">Classification and Regression</h3>
                        <p class="subsection-text">Classification algorithms are used when the outputs are restricted to a limited set of values, while regression algorithms are used when the outputs can take any numerical value within a range. For example, in a classification algorithm that filters emails, the input is an incoming email, and the output is the folder in which to file the email.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Similarity Learning</h3>
                        <p class="subsection-text">Similarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Unsupervised Learning</h2>
                <div class="section-content">
                    <p>Unsupervised learning algorithms find structures in data that has not been labelled, classified or categorised. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data.</p>
                    
                    <p>Central applications of unsupervised machine learning include clustering, dimensionality reduction, and density estimation.</p>

                    <div class="subsection">
                        <h3 class="subsection-title">Cluster Analysis</h3>
                        <p class="subsection-text">Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Dimensionality Reduction</h3>
                        <p class="subsection-text">Dimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables. One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D).</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Self-Supervised Learning</h3>
                        <p class="subsection-text">A special type of unsupervised learning called self-supervised learning involves training a model by generating the supervisory signal from the data itself.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Reinforcement Learning</h2>
                <div class="section-content">
                    <p>Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment to maximise some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.</p>
                    
                    <p>In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcement learning algorithms use dynamic programming techniques. Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.</p>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Semi-Supervised and Other Learning Types</h2>
                <div class="section-content">
                    <div class="subsection">
                        <h3 class="subsection-title">Semi-Supervised Learning</h3>
                        <p class="subsection-text">Semi-supervised learning falls between unsupervised learning (without any labelled training data) and supervised learning (with completely labelled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabelled data, when used in conjunction with a small amount of labelled data, can produce a considerable improvement in learning accuracy.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Self-Learning</h3>
                        <p class="subsection-text">Self-learning, as a machine learning paradigm, was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA). It gives a solution to the problem learning without any external reward, by introducing emotion as an internal reward.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Feature Learning</h3>
                        <p class="subsection-text">Several learning algorithms aim at discovering better representations of the inputs provided during training. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Machine Learning Models</h2>
                <div class="section-content">
                    <p>A machine learning model is a type of mathematical model that, once "trained" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimise errors in its predictions.</p>

                    <div class="subsection">
                        <h3 class="subsection-title">Artificial Neural Networks</h3>
                        <p class="subsection-text">Artificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. An ANN is a model based on a collection of connected units or nodes called "artificial neurons", which loosely model the neurons in a biological brain.</p>
                        <p class="subsection-text">Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Decision Trees</h3>
                        <p class="subsection-text">Decision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). Tree models where the target variable can take a discrete set of values are called classification trees; decision trees where the target variable can take continuous values are called regression trees.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Random Forest Regression</h3>
                        <p class="subsection-text">Random forest regression (RFR) is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and to avoid overfitting. RFR uses bootstrapped sampling; each decision tree is trained on random data from the training set.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Support-Vector Machines</h3>
                        <p class="subsection-text">Support-vector machines (SVMs) are a set of related supervised learning methods used for classification and regression. An SVM training algorithm is a non-probabilistic, binary, linear classifier, although SVMs can efficiently perform non-linear classification using the kernel trick.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Regression Analysis</h3>
                        <p class="subsection-text">Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Bayesian Networks</h3>
                        <p class="subsection-text">A Bayesian network is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Gaussian Processes</h3>
                        <p class="subsection-text">A Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution. Gaussian processes are popular surrogate models in Bayesian optimisation used to do hyperparameter optimisation.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Genetic Algorithms</h3>
                        <p class="subsection-text">A genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Specialized Techniques</h2>
                <div class="section-content">
                    <div class="subsection">
                        <h3 class="subsection-title">Sparse Dictionary Learning</h3>
                        <p class="subsection-text">Sparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix. Sparse dictionary learning has been applied in classification and image denoising.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Anomaly Detection</h3>
                        <p class="subsection-text">In data mining, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations that raise suspicions by differing significantly from the majority of the data. Typically, the anomalous items represent an issue such as bank fraud, a structural defect, medical problems or errors in a text.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Association Rule Learning</h3>
                        <p class="subsection-text">Association rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of "interestingness". For example, finding patterns in supermarket sales data to understand customer buying behaviour.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Learning Classifier Systems</h3>
                        <p class="subsection-text">Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Inductive Logic Programming</h3>
                        <p class="subsection-text">Inductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. ILP is particularly useful in bioinformatics and natural language processing.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Training and Data Considerations</h2>
                <div class="section-content">
                    <p>Typically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data.</p>
                    
                    <div class="subsection">
                        <h3 class="subsection-title">Data Quality and Bias</h3>
                        <p class="subsection-text">Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Machine Learning Ethics</h3>
                        <p class="subsection-text">Machine learning ethics is becoming a field of study and, notably, becoming integrated within machine learning engineering teams to address the ethical implications of AI systems and ensure responsible development and deployment.</p>
                    </div>

                    <div class="subsection">
                        <h3 class="subsection-title">Federated Learning</h3>
                        <p class="subsection-text">Federated learning is an adapted form of distributed artificial intelligence to train machine learning models that decentralises the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralised server. This also increases efficiency by decentralising the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to Google.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2 class="section-title">Applications of Machine Learning</h2>
                <div class="section-content">
                    <p>Machine learning has found widespread applications across numerous domains:</p>
                    <ul>
                        <li><strong>Natural Language Processing:</strong> Text analysis, translation, sentiment analysis, and chatbots</li>
                        <li><strong>Computer Vision:</strong> Image recognition, object detection, facial recognition, and autonomous vehicles</li>
                        <li><strong>Speech Recognition:</strong> Voice assistants, transcription services, and voice-controlled systems</li>
                        <li><strong>Healthcare:</strong> Medical diagnosis, drug discovery, patient monitoring, and treatment planning</li>
                        <li><strong>Finance:</strong> Fraud detection, algorithmic trading, credit scoring, and risk assessment</li>
                        <li><strong>E-commerce:</strong> Recommendation systems, customer segmentation, and demand forecasting</li>
                        <li><strong>Agriculture:</strong> Crop monitoring, yield prediction, and precision farming</li>
                        <li><strong>Manufacturing:</strong> Quality control, predictive maintenance, and supply chain optimization</li>
                        <li><strong>Cybersecurity:</strong> Threat detection, intrusion prevention, and malware analysis</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>

    <script>
        if (typeof TelegramWebApp !== 'undefined') {
            const tg = window.Telegram.WebApp;
            tg.ready();
            tg.setHeaderColor('#000000');
            tg.setBackgroundColor('#000000');
            tg.MainButton.hide();
        }
    </script>
</body>
</html>
